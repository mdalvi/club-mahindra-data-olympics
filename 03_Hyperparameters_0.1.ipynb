{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "\n",
    "import joblib\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import scipy.optimize as spo\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lgbm(X_train, X_test, y_train, y_test, feature_names, categorical_features='auto', model_params=None, fit_params=None, seed=21):\n",
    "\n",
    "    X_train_GBM = lgb.Dataset(X_train, label=y_train, feature_name=feature_names, categorical_feature=categorical_features, free_raw_data=False)\n",
    "    X_test_GBM = lgb.Dataset(X_test, label=y_test, reference=X_train_GBM, feature_name=feature_names, free_raw_data=False)\n",
    "    \n",
    "    if model_params is None:\n",
    "        model_params = {'seed': seed, 'num_threads': 16, 'objective':'root_mean_squared_error', \n",
    "                        'metric': ['root_mean_squared_error'] }\n",
    "        \n",
    "    if fit_params is None:\n",
    "        fit_params = {'verbose_eval': True, 'num_boost_round': 300, 'valid_sets': [X_test_GBM], \n",
    "                      'early_stopping_rounds': 30, 'categorical_feature': categorical_features, 'feature_name': feature_names}\n",
    "        \n",
    "    model = lgb.train(model_params, X_train_GBM, **fit_params)\n",
    "    y_pred = model.predict(X_test, model.best_iteration)\n",
    "    return model, y_pred, mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dataset = pd.read_pickle('data/df/df_train_dataset.pkl')\n",
    "df_validation_dataset = pd.read_pickle('data/df/df_validation_dataset.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = joblib.load('data/iterables/continuous_features.joblib')\n",
    "categorical_features = joblib.load('data/iterables/categorical_features.joblib')\n",
    "target_features = joblib.load('data/iterables/target_features.joblib')\n",
    "target_transformer = joblib.load('models/preprocessing/target_transformer.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((338192, 122), (146765, 122))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_dataset.shape, df_validation_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(338192, 119) (338192,)\n"
     ]
    }
   ],
   "source": [
    "X = df_train_dataset[categorical_features + continuous_features].values\n",
    "y = df_train_dataset[target_features].values.flatten()\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(287463, 119) (50729, 119) (287463,) (50729,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.85, test_size=0.15, shuffle=True, random_state=10)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = categorical_features + continuous_features\n",
    "X_train_GBM = lgb.Dataset(X_train, label=y_train, feature_name=feature_names, categorical_feature=categorical_features, free_raw_data=False)\n",
    "X_test_GBM = lgb.Dataset(X_test, label=y_test, reference=X_train_GBM, feature_name=feature_names, free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "'learning_rate': hp.uniform('learning_rate', 0.001, 0.04),\n",
    "'max_depth' : hp.quniform(\"max_depth\", 3, 8, 1),\n",
    "'bagging_fraction': hp.uniform('bagging_fraction', 0.85, 1.0),  \n",
    "'bagging_freq': hp.quniform('bagging_freq', 1, 16, 1),\n",
    "'lambda_l1': hp.uniform('lambda_l1', 4.0, 16.0), \n",
    "'lambda_l2': hp.uniform('lambda_l2', 4.0, 16.0),\n",
    "'feature_fraction': hp.uniform('feature_fraction', 0.10, 0.30),\n",
    "'num_leaves': hp.quniform(\"num_leaves\", 4, 64, 1),\n",
    "'min_data_in_leaf': hp.quniform(\"min_data_in_leaf\", 32, 512, 1),\n",
    "'max_delta_step': hp.uniform('max_delta_step', 0.0, 0.5),\n",
    "'min_data_per_group': hp.quniform('min_data_per_group', 16, 512, 1),\n",
    "'min_sum_hessian_in_leaf' : hp.uniform('min_sum_hessian_in_leaf', 0.5, 4.0),\n",
    "'min_gain_to_split': hp.uniform('min_gain_to_split', 0.0, 1.0),\n",
    "'max_bin' : hp.quniform(\"max_bin\", 64, 512, 1),\n",
    "'min_data_in_bin': hp.quniform(\"min_data_in_bin\", 1, 32, 1),\n",
    "'max_cat_threshold': hp.quniform('max_cat_threshold', 16, 64, 1),\n",
    "'cat_l2' : hp.uniform('cat_l2', 32.0, 64.0),\n",
    "'cat_smooth': hp.uniform('cat_smooth', 0.0, 4.0),\n",
    "'sparse_threshold' : hp.uniform('sparse_threshold', 0.16, 0.64),\n",
    "'boost_from_average': hp.choice('boost_from_average', [True, False]),\n",
    "\n",
    "\"\"\"\n",
    "space = {\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.001, 0.04),\n",
    "    'max_depth' : hp.quniform(\"max_depth\", 3, 8, 1),\n",
    "    'bagging_fraction': hp.uniform('bagging_fraction', 0.85, 1.0),  \n",
    "    'bagging_freq': hp.quniform('bagging_freq', 1, 16, 1),\n",
    "    'lambda_l1': hp.uniform('lambda_l1', 4.0, 16.0), \n",
    "    'lambda_l2': hp.uniform('lambda_l2', 4.0, 16.0),\n",
    "    'feature_fraction': hp.uniform('feature_fraction', 0.10, 0.30),\n",
    "    'num_leaves': hp.quniform(\"num_leaves\", 4, 64, 1),\n",
    "    'min_data_in_leaf': hp.quniform(\"min_data_in_leaf\", 32, 512, 1),\n",
    "    'max_delta_step': hp.uniform('max_delta_step', 0.0, 0.5),\n",
    "    'min_data_per_group': hp.quniform('min_data_per_group', 16, 512, 1),\n",
    "    'min_sum_hessian_in_leaf' : hp.uniform('min_sum_hessian_in_leaf', 0.5, 4.0),\n",
    "    'min_gain_to_split': hp.uniform('min_gain_to_split', 0.0, 1.0),\n",
    "    'max_bin' : hp.quniform(\"max_bin\", 64, 512, 1),\n",
    "    'min_data_in_bin': hp.quniform(\"min_data_in_bin\", 1, 32, 1),\n",
    "    'max_cat_threshold': hp.quniform('max_cat_threshold', 16, 64, 1),\n",
    "    'cat_l2' : hp.uniform('cat_l2', 32.0, 128.0),\n",
    "    'cat_smooth': hp.uniform('cat_smooth', 0.0, 4.0),\n",
    "    'sparse_threshold' : hp.uniform('sparse_threshold', 0.16, 0.64),\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ints = ['max_depth', 'bagging_freq', 'num_leaves', 'min_data_in_leaf', 'min_data_per_group', 'max_bin', \n",
    "              'min_data_in_bin', 'max_cat_threshold']\n",
    "def objective(space):\n",
    "    model_params = {'num_threads': 16, 'objective': 'root_mean_squared_error', \n",
    "                    'metric': ['root_mean_squared_error'], 'boosting': 'gbdt'}\n",
    "    \n",
    "    for param in space.keys():\n",
    "        if param in param_ints:\n",
    "            model_params[param] = int(space[param])\n",
    "        else:\n",
    "            model_params[param] = space[param]\n",
    "        \n",
    "    fit_params = {'verbose_eval': False, 'num_boost_round': 300, 'valid_sets': [X_test_GBM], 'early_stopping_rounds': 30, \n",
    "                 'categorical_feature': categorical_features, 'feature_name': feature_names}\n",
    "    \n",
    "    model = lgb.train(model_params, X_train_GBM, **fit_params)  \n",
    "    y_pred = model.predict(X_test, model.best_iteration)\n",
    "    \n",
    "    results = {'loss': mean_squared_error(y_test, y_pred) ** .5, 'status': STATUS_OK }\n",
    "    for param in space.keys():\n",
    "        results[param] = space[param]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [12:32<00:00,  7.85s/it, best loss: 0.12259643964754367]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_parameters = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=100, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bagging_fraction': 0.9830356259765703, 'bagging_freq': 9.0, 'cat_l2': 51.40240661408538, 'cat_smooth': 1.8494002054243066, 'feature_fraction': 0.28058304241318754, 'lambda_l1': 5.388803595258235, 'lambda_l2': 6.868490946655484, 'learning_rate': 0.03578751542869848, 'max_bin': 466.0, 'max_cat_threshold': 39.0, 'max_delta_step': 0.27948550018035967, 'max_depth': 6.0, 'min_data_in_bin': 17.0, 'min_data_in_leaf': 114.0, 'min_data_per_group': 404.0, 'min_gain_to_split': 0.1503709410019914, 'min_sum_hessian_in_leaf': 2.4672279431394806, 'num_leaves': 60.0, 'sparse_threshold': 0.380260196469647}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/parameters/best_parameters2.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(best_parameters)\n",
    "joblib.dump(best_parameters, 'models/parameters/best_parameters2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bagging_fraction</th>\n",
       "      <th>bagging_freq</th>\n",
       "      <th>boost_from_average</th>\n",
       "      <th>cat_l2</th>\n",
       "      <th>cat_smooth</th>\n",
       "      <th>feature_fraction</th>\n",
       "      <th>lambda_l1</th>\n",
       "      <th>lambda_l2</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>loss</th>\n",
       "      <th>...</th>\n",
       "      <th>max_delta_step</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_data_in_bin</th>\n",
       "      <th>min_data_in_leaf</th>\n",
       "      <th>min_data_per_group</th>\n",
       "      <th>min_gain_to_split</th>\n",
       "      <th>min_sum_hessian_in_leaf</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>sparse_threshold</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.956319</td>\n",
       "      <td>14.0</td>\n",
       "      <td>True</td>\n",
       "      <td>36.285375</td>\n",
       "      <td>3.968228</td>\n",
       "      <td>0.269915</td>\n",
       "      <td>4.430941</td>\n",
       "      <td>6.032881</td>\n",
       "      <td>0.036590</td>\n",
       "      <td>0.122365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286282</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.014238</td>\n",
       "      <td>2.515303</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.161188</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.958898</td>\n",
       "      <td>14.0</td>\n",
       "      <td>True</td>\n",
       "      <td>37.338306</td>\n",
       "      <td>3.996000</td>\n",
       "      <td>0.292562</td>\n",
       "      <td>7.711478</td>\n",
       "      <td>5.420360</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>0.122481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467735</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>0.001816</td>\n",
       "      <td>2.370192</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.168208</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.951783</td>\n",
       "      <td>16.0</td>\n",
       "      <td>True</td>\n",
       "      <td>32.003918</td>\n",
       "      <td>3.901894</td>\n",
       "      <td>0.257474</td>\n",
       "      <td>6.889187</td>\n",
       "      <td>4.347178</td>\n",
       "      <td>0.039883</td>\n",
       "      <td>0.122528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.011982</td>\n",
       "      <td>2.619818</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.160935</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.980093</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>46.469673</td>\n",
       "      <td>3.618718</td>\n",
       "      <td>0.248205</td>\n",
       "      <td>7.333754</td>\n",
       "      <td>6.166060</td>\n",
       "      <td>0.030026</td>\n",
       "      <td>0.122665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266047</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.188792</td>\n",
       "      <td>2.006417</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.259151</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.986926</td>\n",
       "      <td>14.0</td>\n",
       "      <td>True</td>\n",
       "      <td>37.807435</td>\n",
       "      <td>3.921964</td>\n",
       "      <td>0.296010</td>\n",
       "      <td>10.281893</td>\n",
       "      <td>5.730291</td>\n",
       "      <td>0.036440</td>\n",
       "      <td>0.122711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474006</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.071248</td>\n",
       "      <td>1.493297</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.195474</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.960908</td>\n",
       "      <td>14.0</td>\n",
       "      <td>True</td>\n",
       "      <td>39.313736</td>\n",
       "      <td>2.272155</td>\n",
       "      <td>0.274706</td>\n",
       "      <td>5.308877</td>\n",
       "      <td>5.370593</td>\n",
       "      <td>0.027804</td>\n",
       "      <td>0.122714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464237</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.376217</td>\n",
       "      <td>2.336389</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.160385</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.945661</td>\n",
       "      <td>14.0</td>\n",
       "      <td>True</td>\n",
       "      <td>32.462766</td>\n",
       "      <td>3.354127</td>\n",
       "      <td>0.265939</td>\n",
       "      <td>4.219128</td>\n",
       "      <td>4.175170</td>\n",
       "      <td>0.035380</td>\n",
       "      <td>0.122794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288622</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>0.004057</td>\n",
       "      <td>2.526733</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.289372</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.987880</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>42.549699</td>\n",
       "      <td>3.241866</td>\n",
       "      <td>0.292939</td>\n",
       "      <td>5.142206</td>\n",
       "      <td>6.418653</td>\n",
       "      <td>0.038030</td>\n",
       "      <td>0.122847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350890</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.530299</td>\n",
       "      <td>2.273805</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.235947</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.936067</td>\n",
       "      <td>9.0</td>\n",
       "      <td>True</td>\n",
       "      <td>37.050666</td>\n",
       "      <td>3.979062</td>\n",
       "      <td>0.208930</td>\n",
       "      <td>5.939065</td>\n",
       "      <td>6.916768</td>\n",
       "      <td>0.039314</td>\n",
       "      <td>0.122855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.394417</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.058089</td>\n",
       "      <td>3.412803</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.203741</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.971596</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>59.154366</td>\n",
       "      <td>2.516636</td>\n",
       "      <td>0.285642</td>\n",
       "      <td>7.283007</td>\n",
       "      <td>15.849539</td>\n",
       "      <td>0.026032</td>\n",
       "      <td>0.123000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.434820</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.291578</td>\n",
       "      <td>2.072692</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.351678</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    bagging_fraction  bagging_freq  boost_from_average     cat_l2  cat_smooth  \\\n",
       "24          0.956319          14.0                True  36.285375    3.968228   \n",
       "25          0.958898          14.0                True  37.338306    3.996000   \n",
       "21          0.951783          16.0                True  32.003918    3.901894   \n",
       "36          0.980093          15.0                True  46.469673    3.618718   \n",
       "26          0.986926          14.0                True  37.807435    3.921964   \n",
       "27          0.960908          14.0                True  39.313736    2.272155   \n",
       "23          0.945661          14.0                True  32.462766    3.354127   \n",
       "32          0.987880          15.0                True  42.549699    3.241866   \n",
       "38          0.936067           9.0                True  37.050666    3.979062   \n",
       "47          0.971596           1.0                True  59.154366    2.516636   \n",
       "\n",
       "    feature_fraction  lambda_l1  lambda_l2  learning_rate      loss  ...  \\\n",
       "24          0.269915   4.430941   6.032881       0.036590  0.122365  ...   \n",
       "25          0.292562   7.711478   5.420360       0.036600  0.122481  ...   \n",
       "21          0.257474   6.889187   4.347178       0.039883  0.122528  ...   \n",
       "36          0.248205   7.333754   6.166060       0.030026  0.122665  ...   \n",
       "26          0.296010  10.281893   5.730291       0.036440  0.122711  ...   \n",
       "27          0.274706   5.308877   5.370593       0.027804  0.122714  ...   \n",
       "23          0.265939   4.219128   4.175170       0.035380  0.122794  ...   \n",
       "32          0.292939   5.142206   6.418653       0.038030  0.122847  ...   \n",
       "38          0.208930   5.939065   6.916768       0.039314  0.122855  ...   \n",
       "47          0.285642   7.283007  15.849539       0.026032  0.123000  ...   \n",
       "\n",
       "    max_delta_step  max_depth  min_data_in_bin  min_data_in_leaf  \\\n",
       "24        0.286282        7.0             24.0              94.0   \n",
       "25        0.467735        7.0             24.0              90.0   \n",
       "21        0.298635        7.0             22.0              41.0   \n",
       "36        0.266047        8.0              5.0             155.0   \n",
       "26        0.474006        6.0             25.0              90.0   \n",
       "27        0.464237        7.0             19.0              89.0   \n",
       "23        0.288622        7.0             21.0              33.0   \n",
       "32        0.350890        6.0             20.0              78.0   \n",
       "38        0.394417        6.0             11.0             324.0   \n",
       "47        0.434820        8.0             16.0              62.0   \n",
       "\n",
       "    min_data_per_group  min_gain_to_split  min_sum_hessian_in_leaf  \\\n",
       "24               208.0           0.014238                 2.515303   \n",
       "25               194.0           0.001816                 2.370192   \n",
       "21               225.0           0.011982                 2.619818   \n",
       "36                94.0           0.188792                 2.006417   \n",
       "26               147.0           0.071248                 1.493297   \n",
       "27               201.0           0.376217                 2.336389   \n",
       "23               237.0           0.004057                 2.526733   \n",
       "32               120.0           0.530299                 2.273805   \n",
       "38               164.0           0.058089                 3.412803   \n",
       "47               102.0           0.291578                 2.072692   \n",
       "\n",
       "    num_leaves  sparse_threshold  status  \n",
       "24        28.0          0.161188      ok  \n",
       "25        25.0          0.168208      ok  \n",
       "21        55.0          0.160935      ok  \n",
       "36        20.0          0.259151      ok  \n",
       "26        24.0          0.195474      ok  \n",
       "27        31.0          0.160385      ok  \n",
       "23        30.0          0.289372      ok  \n",
       "32        32.0          0.235947      ok  \n",
       "38        40.0          0.203741      ok  \n",
       "47        13.0          0.351678      ok  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(trials.results)\n",
    "df.nsmallest(10, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot(x='sparse_threshold', y='loss', kind='scatter');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot(x='min_data_in_bin', y='loss', kind='scatter');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
